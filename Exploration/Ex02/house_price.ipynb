{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '~/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "sub_data_path = join(data_dir, 'test.csv')      # 테스트, 즉 submission 시 사용할 데이터 경로\n",
    "\n",
    "print(train_data_path)\n",
    "print(sub_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 살펴보기\n",
    "pandas의 read_csv 함수를 사용해 데이터를 읽어오고, 각 변수들이 나타내는 의미를 살펴보겠습니다.\n",
    "1. ID : 집을 구분하는 번호\n",
    "2. date : 집을 구매한 날짜\n",
    "3. price : 타겟 변수인 집의 가격\n",
    "4. bedrooms : 침실의 수\n",
    "5. bathrooms : 침실당 화장실 개수\n",
    "6. sqft_living : 주거 공간의 평방 피트\n",
    "7. sqft_lot : 부지의 평방 피트\n",
    "8. floors : 집의 층 수\n",
    "9. waterfront : 집의 전방에 강이 흐르는지 유무 (a.k.a. 리버뷰)\n",
    "10. view : 집이 얼마나 좋아 보이는지의 정도\n",
    "11. condition : 집의 전반적인 상태\n",
    "12. grade : King County grading 시스템 기준으로 매긴 집의 등급\n",
    "13. sqft_above : 지하실을 제외한 평방 피트\n",
    "14. sqft_basement : 지하실의 평방 피트\n",
    "15. yr_built : 집을 지은 년도\n",
    "16. yr_renovated : 집을 재건축한 년도\n",
    "17. zipcode : 우편번호\n",
    "18. lat : 위도\n",
    "19. long : 경도\n",
    "20. sqft_living15 : 2015년 기준 주거 공간의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)\n",
    "21. sqft_lot15 : 2015년 기준 부지의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(train_data_path)\n",
    "sub = pd.read_csv(sub_data_path)\n",
    "print('train data dim : {}'.format(data.shape))\n",
    "print('sub data dim : {}'.format(sub.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "price 데이터 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(data['price'], fill=True)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of House Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그래프가 왼쪽으로 크게 치우쳐 있으므로 로그 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data['price'] = np.log1p(data['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상관관계 파악을 위한 히트맵 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# correlation이 높은 상위 10개의 heatmap\n",
    "# continuous + sequential variables --> spearman\n",
    "# abs는 반비례관계도 고려하기 위함\n",
    "import scipy as sp\n",
    "\n",
    "cor_abs = abs(data.corr(method='spearman')) \n",
    "cor_cols = cor_abs.nlargest(n=10, columns='price').index # price과 correlation이 높은 column 10개 뽑기(내림차순)\n",
    "# spearman coefficient matrix\n",
    "cor = np.array(sp.stats.spearmanr(data[cor_cols].values))[0] # 10 x 10\n",
    "print(cor_cols.values)\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set(font_scale=1.25)\n",
    "sns.heatmap(cor, fmt='.2f', annot=True, square=True , annot_kws={'size' : 8} ,xticklabels=cor_cols.values, yticklabels=cor_cols.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 간단한 전처리 \n",
    "각 변수들에 대해 결측 유무를 확인하고, 분포를 확인해보면서 간단하게 전처리를 하겠습니다.\n",
    "### 결측치 확인\n",
    "먼저 데이터에 결측치가 있는지를 확인하겠습니다.<br>\n",
    "missingno 라이브러리의 matrix 함수를 사용하면, 데이터의 결측 상태를 시각화를 통해 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 변수에 결측치가 없는 것으로 보이지만, 혹시 모르니 확실하게 살펴보겠습니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    print('{} : {}'.format(c, len(data.loc[pd.isnull(data[c]), c].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "price와 sqft_living의 상관관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "temp_data = pd.concat([data['price'], data['sqft_living']], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.regplot(x='sqft_living', y=\"price\", data=temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상치로 보이는 값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[data['sqft_living'] > 13000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상치 삭제(오히려 성능 떨어져서 복구)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# data = data.loc[data['id']!=8912]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "price와 grade의 상관관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "temp_data = pd.concat([data['price'], data['grade']], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x='grade', y=\"price\", data=temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상치로 보이는 값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[(data['price']>12) & (data['grade'] == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[(data['price']>14.7) & (data['grade'] == 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[(data['price']>15.5) & (data['grade'] == 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상치 삭제(오히려 성능 떨어져서 복구)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# data = data.loc[data['id']!=2302]\n",
    "# data = data.loc[data['id']!=4123]\n",
    "# data = data.loc[data['id']!=7173]\n",
    "# data = data.loc[data['id']!=2775]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "price 값을 target으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "y = data['price']\n",
    "\n",
    "del data['price']\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_len = len(data)\n",
    "data = pd.concat((data, sub), axis=0)\n",
    "\n",
    "print(len(data))\n",
    "print(train_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "renovated year을 리모델링 됐는지 안됐는지 one-hot vector로 표현(성능이 떨어져서 삭제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# data['is_renovated'] = data['yr_renovated'].apply(lambda x: 0 if x == 0 else 1)\n",
    "# del data['yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id, date 변수 정리\n",
    "id 변수는 모델이 집값을 예측하는데 도움을 주지 않으므로 제거합니다.<br>\n",
    "date 변수는 연월일시간으로 값을 가지고 있는데, 연월만 고려하는 범주형 변수로 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sub_id = data['id'][train_len:]\n",
    "del data['id']\n",
    "data['date'] = data['date'].apply(lambda x : str(x[:6])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 변수들의 분포 확인\n",
    "한쪽으로 치우친 분포는 모델이 결과를 예측하기에 좋지 않은 영향을 미치므로 다듬어줄 필요가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(9, 2, figsize=(12, 50))   # 가로스크롤 때문에 그래프 확인이 불편하다면 figsize의 x값을 조절해 보세요. \n",
    "\n",
    "# id 변수(count==0인 경우)는 제외하고 분포를 확인합니다.\n",
    "count = 1\n",
    "columns = data.columns\n",
    "for row in range(9):\n",
    "    for col in range(2):\n",
    "        sns.kdeplot(data=data[columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count += 1\n",
    "        if count == 19 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "price, bedrooms, sqft_living, sqft_lot, sqft_above, sqft_basement 변수가 한쪽으로 치우친 경향을 보였습니다.<br>\n",
    "log-scaling을 통해 데이터 분포를 정규분포에 가깝게 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']\n",
    "\n",
    "for c in skew_columns:\n",
    "    data[c] = np.log1p(data[c].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(12, 20))   # 가로스크롤 때문에 그래프 확인이 불편하다면 figsize의 x값을 조절해 보세요. \n",
    "\n",
    "count = 0\n",
    "columns = data.columns\n",
    "for row in range(4):\n",
    "    if count >= len(skew_columns):\n",
    "        break\n",
    "    for col in range(2):\n",
    "        sns.kdeplot(data=data[skew_columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(skew_columns[count], fontsize=15)\n",
    "        count += 1\n",
    "        if count >= len(skew_columns):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어느정도 치우침이 줄어든 분포를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sub = data.iloc[train_len:, :]\n",
    "x = data.iloc[:train_len, :]\n",
    "\n",
    "print(train_len)\n",
    "print(x.shape)\n",
    "print(sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA를 통해 더 중요한 feature만 남도록 조절<br>\n",
    "오히려 사용시 오버피팅이 일어나 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # 1. 스케일링\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(x)\n",
    "# X_test_scaled = scaler.transform(sub)\n",
    "\n",
    "# # 2. PCA\n",
    "# pca = PCA(n_components=0.9)\n",
    "# X_pca = pca.fit_transform(X_scaled)\n",
    "# X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# x = X_pca\n",
    "# sub = X_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여기서부터 학습에 필요한 함수들<br>\n",
    "첫번째는 rmse 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두번째는 스코어 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores(models, train, y, include_averaging=False):\n",
    "    df = {}\n",
    "    preds_list = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        preds_list.append(y_pred)\n",
    "        \n",
    "        df[model_name] = rmse(y_test, y_pred)\n",
    "        \n",
    "    if include_averaging:\n",
    "        y_pred_avg = np.mean(preds_list, axis=0)\n",
    "        df['AveragingEnsemble'] = rmse(y_test, y_pred_avg)\n",
    "    \n",
    "    score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "\n",
    "    return score_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 모델에 대해 하이퍼 파라미터를 튜닝하는 함수(random search 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def random_search(model, params, X, y):\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=params,\n",
    "        n_iter=10,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    search.fit(X_train, y_train)\n",
    "    return {\n",
    "        \"model_name\": model.__class__.__name__,\n",
    "        \"best_score\": -search.best_score_,\n",
    "        \"best_params\": search.best_params_,\n",
    "        \"best_estimator\": search.best_estimator_\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앙상블 모델에 사용할 후보들\n",
    "1. XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "\n",
    "scores = []\n",
    "\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "scores.append(random_search(xgb_model, xgb_params, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "lgb_model = LGBMRegressor(random_state=42)\n",
    "\n",
    "lgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [-1, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'subsample': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "scores.append(random_search(lgb_model, lgb_params, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "scores.append(random_search(gb_model, gb_params, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "scores.append(random_search(rf_model, rf_params, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "hgb_model = HistGradientBoostingRegressor(random_state=42)\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'max_iter': [100, 200],\n",
    "    'l2_regularization': [0.0, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "scores.append(random_search(hgb_model, hgb_params, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "et_model = ExtraTreesRegressor(random_state=42)\n",
    "\n",
    "et_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "scores.append(random_search(et_model, et_params, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 모델들 중 가장 RMSE가 낮은 4개의 모델 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(scores)\n",
    "top_models = results_df.sort_values(\"best_score\").head(4)  # RMSE 낮은 모델 상위 4개\n",
    "print(top_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging을 이용한 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# best_estimator 리스트로부터 모델들 준비\n",
    "top_models = results_df.sort_values(\"best_score\").head(4)[\"best_estimator\"].tolist()\n",
    "\n",
    "# Averaging 포함한 성능 비교\n",
    "score_df = get_scores(top_models, x, y, include_averaging=True)\n",
    "print(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습과 예측값 저장을 모두 포함한 함수<br>\n",
    "앙상블 기법 중 Averaging, Weighted averaging, Stacking 3가지 기법을 실험함<br>\n",
    "Stacking에 사용되는 메타모델로 Ridge, SVR, ElasticNet 사용해봄<br>\n",
    "SVR의 성능이 가장 좋은 것으로 결론지음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "def save_submission(models, train, y, test, model_name=\"Ensemble\", mode=\"averaging\", weights=None):\n",
    "    \"\"\"\n",
    "    Averaging, Weighted Averaging 또는 Stacking 방식으로 예측 후 submission 파일 저장.\n",
    "\n",
    "    Parameters:\n",
    "    - models: base 모델 리스트\n",
    "    - train, y: 학습 데이터\n",
    "    - test: 예측용 데이터\n",
    "    - model_name: 저장될 파일 이름에 포함될 이름\n",
    "    - mode: 'averaging', 'weighted', 'stacking'\n",
    "    - weights: weighted averaging 시 사용할 가중치 리스트\n",
    "    \"\"\"\n",
    "    data_dir = os.getenv('HOME') + '/aiffel/kaggle_kakr_housing/data'\n",
    "    submission_path = join(data_dir, 'sample_submission.csv')\n",
    "    submission = pd.read_csv(submission_path)\n",
    "\n",
    "    if mode in [\"averaging\", \"weighted\"]:\n",
    "        predictions = []\n",
    "        for model in models:\n",
    "            model.fit(train, y)\n",
    "            pred = model.predict(test)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        preds_array = np.array(predictions)\n",
    "\n",
    "        if mode == \"weighted\":\n",
    "            if weights is None or len(weights) != len(models):\n",
    "                raise ValueError(\"weights must be a list of same length as models when mode='weighted'\")\n",
    "            avg_prediction = np.average(preds_array, axis=0, weights=weights)\n",
    "            y_train_pred = np.average([model.predict(train) for model in models], axis=0, weights=weights)\n",
    "        else:\n",
    "            avg_prediction = np.mean(preds_array, axis=0)\n",
    "            y_train_pred = np.mean([model.predict(train) for model in models], axis=0)\n",
    "\n",
    "    elif mode == \"stacking\":\n",
    "        estimators = [(f\"model_{i}\", m) for i, m in enumerate(models)]\n",
    "        meta_model = SVR(C=5.0, epsilon=0.01)\n",
    "\n",
    "        stack_model = StackingRegressor(\n",
    "            estimators=estimators,\n",
    "            final_estimator=meta_model,\n",
    "            cv=5,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        stack_model.fit(train, y)\n",
    "        avg_prediction = stack_model.predict(test)\n",
    "        y_train_pred = stack_model.predict(train)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'averaging', 'weighted' or 'stacking'\")\n",
    "\n",
    "    # 역변환\n",
    "    avg_prediction = np.expm1(avg_prediction)\n",
    "    rmsle_score = np.sqrt(mean_squared_log_error(np.expm1(y), np.expm1(y_train_pred)))\n",
    "\n",
    "    submission['price'] = avg_prediction\n",
    "    submission_csv_path = f'{data_dir}/submission_{model_name}_{mode}_RMSLE_{rmsle_score:.4f}.csv'\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "\n",
    "    print(f'Submission saved to: {submission_csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케글 코드를 보던 중 알게 된 2-stage stacking 앙상블 기법 코드(성능저하로 삭제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# def run_2stage_stacking(models, train, y_log, test, sample_submission_path, model_name=\"2StageStacking\", seed=42):\n",
    "#     \"\"\"\n",
    "#     RandomSearch로 튜닝된 모델들로 2-stage stacking 수행 후 제출 파일 저장\n",
    "    \n",
    "#     Parameters:\n",
    "#     - models: best_estimator_ 리스트 (튜닝된 모델들)\n",
    "#     - train, y_log: 학습 데이터 (y는 np.log1p로 변환된 상태)\n",
    "#     - test: 예측할 테스트 데이터\n",
    "#     - sample_submission_path: sample_submission.csv 경로\n",
    "#     - model_name: 저장할 제출 파일 이름 구분자\n",
    "#     - seed: 랜덤 시드\n",
    "#     \"\"\"\n",
    "#     oof_preds = []\n",
    "#     test_preds = []\n",
    "#     kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "#     for i, model in enumerate(models):\n",
    "#         oof = np.zeros(len(train))\n",
    "#         test_pred_fold = np.zeros((5, len(test)))  # 5-fold test 예측 저장용\n",
    "\n",
    "#         for fold, (tr_idx, val_idx) in enumerate(kf.split(train)):\n",
    "#             X_tr, X_val = train.iloc[tr_idx], train.iloc[val_idx]\n",
    "#             y_tr, y_val = y_log.iloc[tr_idx], y_log.iloc[val_idx]\n",
    "\n",
    "#             model.fit(X_tr, y_tr)\n",
    "#             oof[val_idx] = model.predict(X_val)\n",
    "#             test_pred_fold[fold] = model.predict(test)\n",
    "\n",
    "#         oof_preds.append(oof)\n",
    "#         test_preds.append(np.mean(test_pred_fold, axis=0))\n",
    "\n",
    "#     # 스택킹 입력 데이터 구성\n",
    "#     oof_stack = pd.DataFrame(np.array(oof_preds).T, columns=[f'model_{i}' for i in range(len(models))])\n",
    "#     test_stack = pd.DataFrame(np.array(test_preds).T, columns=[f'model_{i}' for i in range(len(models))])\n",
    "\n",
    "#     # 메타 모델 학습\n",
    "#     meta_model = Ridge(alpha=1.0)\n",
    "#     meta_model.fit(oof_stack, y_log)\n",
    "#     final_log_pred = meta_model.predict(test_stack)\n",
    "#     train_log_pred = meta_model.predict(oof_stack)\n",
    "\n",
    "#     # RMSLE 계산\n",
    "#     rmsle_score = np.sqrt(mean_squared_log_error(np.expm1(y_log), np.expm1(train_log_pred)))\n",
    "\n",
    "#     # 제출 저장\n",
    "#     submission = pd.read_csv(sample_submission_path)\n",
    "#     submission['price'] = np.expm1(final_log_pred)\n",
    "\n",
    "#     data_dir = os.path.dirname(sample_submission_path)\n",
    "#     output_path = f'{data_dir}/submission_{model_name}_RMSLE_{rmsle_score:.4f}.csv'\n",
    "#     submission.to_csv(output_path, index=False)\n",
    "\n",
    "#     print(f'[✅] 2-Stage Stacking submission saved to: {output_path}')\n",
    "#     return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 모델에 대한 앙상블 기법을 활용한 결과값 생성<br>\n",
    "지금까지 가장 좋은 방식은 4개 모델을 사용하고 메타모델로 SVR을 사용한 Stacking 앙상블 (private 110889.16529)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "top_models = results_df.sort_values(\"best_score\").head(4)[\"best_estimator\"].tolist()\n",
    "\n",
    "# weights = [0.45, 0.3, 0.25]\n",
    "\n",
    "save_submission(\n",
    "    models=top_models,\n",
    "    train=x,\n",
    "    y=y,                 # 로그 변환 적용한 y\n",
    "    test=sub,             # 실제 예측에 쓸 테스트 데이터\n",
    "    model_name=\"Top4_svr\",\n",
    "    mode=\"stacking\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
