{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f41963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.12.1\n",
      "Cuda version: 11.3\n",
      "transformers version: 4.28.0\n",
      "GPU 사용 가능여부: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "print(\"Torch version:{}\".format(torch.__version__)) # Torch version:1.12.1\n",
    "print(\"Cuda version: {}\".format(torch.version.cuda)) # Cuda version: 11.3\n",
    "print(\"transformers version: {}\".format(transformers.__version__)) # transformers 4.28.0\n",
    "print(\"GPU 사용 가능여부: {}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f647a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.9/site-packages (0.4.3)\n",
      "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from evaluate) (1.21.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.70.12.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.3.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2.13.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from evaluate) (1.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2.26.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2021.11.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.9/site-packages (from evaluate) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.15.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from rouge_score) (3.6.5)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge_score) (0.12.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (12.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->evaluate) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.10)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (2021.11.10)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->evaluate) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4064eb9b",
   "metadata": {},
   "source": [
    "### 모델 불러오기 - skt/kogpt2-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e56409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05af1d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': 1024,\n",
       " 'gpt2-medium': 1024,\n",
       " 'gpt2-large': 1024,\n",
       " 'gpt2-xl': 1024,\n",
       " 'distilgpt2': 1024}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e72911",
   "metadata": {},
   "source": [
    "### SFT 데이터 - 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7811dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '불고기용 고기 한우에요?',\n",
       "  'completion': \"'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\",\n",
       "  'tokens': 193},\n",
       " {'prompt': '쓰던 앱이 유료로 전환됐어',\n",
       "  'completion': \"'어떤 앱인지 모르기 때문에 정확한 답변을 드리기 어렵습니다. 하지만, 일반적으로 유료 전환된 앱은 기존 무료 앱에서 추가적인 기능이나 서비스를 제공하는 경우가 많습니다. 이 경우, 유료 전환 이전 가격이 매우 저렴하거나 무료인 경우가 많으므로, 앱을 계속 사용하려면 추가적인 비용을 지불해야 할 수 있습니다. 하지만, 유료 전환 이후에는 기존 사용자 또는 새로운 사용자 모두가 추가 기능과 높은 품질의 서비스를 이용할 수 있게 됩니다. 따라서, 앱 개발자는 유료 모델로 전환함으로써 앱의 수익을 증가시키고 더 나은 서비스를 제공할 수 있습니다.\",\n",
       "  'tokens': 288},\n",
       " {'prompt': '여친이랑 다툼',\n",
       "  'completion': \"'저는 인공지능이기 때문에 여친과의 다툼에 대해서는 조언을 드릴 수는 없습니다. 하지만 다투게 되면 상대방의 말을 경청하는 태도와 서로의 감정을 존중하는 것이 중요합니다. 논리적이고 차분한 대화를 통해 문제를 해결해보세요. 그리고 서로를 이해하고 서로의 의견을 수용하는 것이 중요합니다.\",\n",
       "  'tokens': 153}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "data_path_1_SFT = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl' \n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59f0e5",
   "metadata": {},
   "source": [
    "### RM 데이터 - 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad2ce794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?',\n",
       "  'completion_0': 'Allow me to answer your question. I know that you are curious about me.',\n",
       "  'completion_1': '번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다.',\n",
       "  'completion_2': '라이언에게 말했다.',\n",
       "  'ranking': [2, 1, 0]},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?',\n",
       "  'completion_0': '개포주공아파트는 다섯 단지로 이루어져 있습니다.',\n",
       "  'completion_1': '이날 목송에서 구글상위노',\n",
       "  'completion_2': '개포주공아파트는 총 27개 단지로 이루어져 있습니다.',\n",
       "  'ranking': [2, 0, 1]},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?',\n",
       "  'completion_0': 'The diameter of the Metallic domain is bigger than the Hyperonic domain.',\n",
       "  'completion_1': '이 질문은 조금 불분명합니다. 김영삼 대통령이 후보 시절에 어떤 발언을 했고, 누가 그 발언을 문제삼았는지에 따라 답이 다를 수 있습니다.\\\\n\\\\n만약 김영삼 대통령이 후보 시절에 지역표심을 겨냥한 발언을 했다는 가정하에, 그 발언을 문제삼은 후보가 누구였는지를 대답하자면, 그 답은 이화선 당시 민주당 대통령 후보가 될 것입니다. 1992년 총선 때, 김영삼 대선후보는 \"집값이 오른 노량진역 부근의 부동산 가격은 세월호 폭침 후 \\\\\\'강남 도시재생\\\\\\' 일환으로 상승했다\"는 발언을 했습니다. 하지만 이화선 후보는 이 발언을 \"전국적으로 경제적 발전이 이루어지지 않은 지방민의 마음을 멀리해지려는 무례한 발언\"이라고 비판하며 문제삼았습니다.\\\\n\\\\n하지만, 이 질문을 답변하는 데 있어서 보다 명확한 정보가 있으면 답변을 보완할 수 있습니다.',\n",
       "  'completion_2': '김영삼의 후보 시절에 지역표심을 겨냥한 발언은 대통령 당선 전까지 대한민국 정부가 추구하고 있는 민주주의 광범위하게 확립과 보수의 사상을 이어가는 데 있어 지역경제 발전과 공공서비스 신속 개선을 위해 합리적인 국가 정책에 따르는 방향성을 제시하고 있습니다.',\n",
       "  'ranking': [1, 2, 0]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_2_RM = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59909a3",
   "metadata": {},
   "source": [
    "### PPO 데이터 - 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c72a602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_3_PPO = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bef8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574c2aa",
   "metadata": {},
   "source": [
    "### SFT 모델 토크나이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b156cf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58cfd40",
   "metadata": {},
   "source": [
    "### SFT 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2059f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d5f0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8322ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 12000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SFT_dataset(data_path_1_SFT='/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl', tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69faa304",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/aiffel/KoChatGPT/test\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16 = True\n",
    "    )\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21875b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()      # 캐시 비움 (실제 메모리 해제는 아님)\n",
    "torch.cuda.ipc_collect()      # inter-process communication 캐시 정리 (필요한 경우)\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f97e847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 08:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.947900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.759300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.742400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.656700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('/aiffel/KoChatGPT/output_1_SFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "739d342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer # rouge_score 라이브러리 임포트\n",
    "\n",
    "def calculate_and_print_rouge_scores(generated_texts: list,\n",
    "                                     reference_texts: list,\n",
    "                                     use_stemmer: bool = False,\n",
    "                                     print_individual_scores: bool = True):\n",
    "    \"\"\"\n",
    "    생성된 텍스트와 참조 텍스트 간의 ROUGE 점수를 계산하고 결과를 출력합니다.\n",
    "\n",
    "    Args:\n",
    "        generated_texts (list): 모델이 생성한 텍스트(응답)의 리스트입니다.\n",
    "        reference_texts (list): 참조 (정답) 텍스트의 리스트입니다.\n",
    "        use_stemmer (bool): ROUGE 계산 시 형태소 분석기(stemmer) 사용 여부입니다.\n",
    "                            True로 설정 시, NLTK 등의 라이브러리가 필요할 수 있으며,\n",
    "                            한국어의 경우 적절한 한국어 형태소 분석기 설정이 필요합니다.\n",
    "                            기본값은 False입니다.\n",
    "        print_individual_scores (bool): 각 샘플별 ROUGE 점수 출력 여부입니다. 기본값은 True입니다.\n",
    "\n",
    "    Returns:\n",
    "        dict: 평균 ROUGE Precision, Recall, F1-score를 담은 딕셔너리입니다.\n",
    "              (예: {'rouge1_precision': 0.XX, 'rouge1_recall': 0.YY, 'rouge1_f1': 0.ZZ, ...})\n",
    "              텍스트 목록이 비어 있거나 길이가 다를 경우 None을 반환합니다.\n",
    "    \"\"\"\n",
    "    if not generated_texts or not reference_texts:\n",
    "        print(\"🚫 생성된 텍스트 또는 참조 텍스트 목록이 비어있습니다. ROUGE 점수를 계산할 수 없습니다.\")\n",
    "        return None\n",
    "\n",
    "    if len(generated_texts) != len(reference_texts):\n",
    "        print(f\"🚫 생성된 텍스트의 수({len(generated_texts)})와 참조 텍스트의 수({len(reference_texts)})가 일치하지 않아 ROUGE 점수를 계산할 수 없습니다.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # rouge_scorer 초기화\n",
    "        # 지원되는 메트릭: 'rouge1', 'rouge2', ..., 'rougeL', 'rougeLsum'\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=use_stemmer)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ RougeScorer 초기화 중 오류 발생: {e}\")\n",
    "        print(\"ROUGE 점수 계산을 진행할 수 없습니다.\")\n",
    "        return None\n",
    "\n",
    "    # 모든 샘플의 ROUGE 점수를 저장할 딕셔너리\n",
    "    all_scores_p = {'rouge1': [], 'rouge2': [], 'rougeL': []} # Precision\n",
    "    all_scores_r = {'rouge1': [], 'rouge2': [], 'rougeL': []} # Recall\n",
    "    all_scores_f = {'rouge1': [], 'rouge2': [], 'rougeL': []} # F1-score\n",
    "\n",
    "    if print_individual_scores:\n",
    "        print(\"\\n\\n--- 💯 개별 샘플 ROUGE 스코어 ---\")\n",
    "\n",
    "    for i in range(len(generated_texts)):\n",
    "        candidate = str(generated_texts[i])  # 생성된 텍스트\n",
    "        reference = str(reference_texts[i])  # 참조 텍스트\n",
    "\n",
    "        # ROUGE 점수 계산\n",
    "        # scores는 각 rouge 타입 (예: 'rouge1')에 대해 Score(precision=..., recall=..., fmeasure=...) 객체를 포함하는 딕셔너리\n",
    "        scores = scorer.score(reference, candidate)\n",
    "\n",
    "        if print_individual_scores:\n",
    "            print(f\"\\n📜 샘플 {i+1}:\")\n",
    "            print(f\"  ROUGE 점수:\")\n",
    "            for rouge_type, score_obj in scores.items():\n",
    "                print(f\"    {rouge_type.upper()}: P={score_obj.precision:.4f}, R={score_obj.recall:.4f}, F1={score_obj.fmeasure:.4f}\")\n",
    "\n",
    "        # 각 타입별 점수 저장\n",
    "        for rouge_type in ['rouge1', 'rouge2', 'rougeL']:\n",
    "            all_scores_p[rouge_type].append(scores[rouge_type].precision)\n",
    "            all_scores_r[rouge_type].append(scores[rouge_type].recall)\n",
    "            all_scores_f[rouge_type].append(scores[rouge_type].fmeasure)\n",
    "\n",
    "    # 평균 ROUGE 점수 계산\n",
    "    average_results = {}\n",
    "    if all_scores_f['rouge1']:  # 점수가 하나라도 계산되었다면\n",
    "        print(\"\\n\\n--- 📉 전체 샘플 평균 ROUGE 스코어 ---\")\n",
    "        for rouge_type in ['rouge1', 'rouge2', 'rougeL']:\n",
    "            avg_p = sum(all_scores_p[rouge_type]) / len(all_scores_p[rouge_type])\n",
    "            avg_r = sum(all_scores_r[rouge_type]) / len(all_scores_r[rouge_type])\n",
    "            avg_f = sum(all_scores_f[rouge_type]) / len(all_scores_f[rouge_type])\n",
    "\n",
    "            average_results[f'{rouge_type}_precision'] = avg_p\n",
    "            average_results[f'{rouge_type}_recall'] = avg_r\n",
    "            average_results[f'{rouge_type}_f1'] = avg_f\n",
    "            \n",
    "            print(f\"  평균 {rouge_type.upper()}: P={avg_p:.4f}, R={avg_r:.4f}, F1={avg_f:.4f}\")\n",
    "        \n",
    "        return average_results\n",
    "    else:\n",
    "        print(\"⚠️ 계산된 ROUGE 점수가 없어 평균을 반환할 수 없습니다.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f584a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_id = tokenizer.eos_token_id\n",
    "pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bba9fd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 AI 어시스턴트이기 때문에 고기를 먹을 수 없습니다. 하지만 일반적으로 불고기는 건강하고 맛있는 음식 중 하나입니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨은 46대 부통령직을 수행했습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어?\n",
      "\n",
      "### Response(응답):'저는 인공지능 어시스턴트이기 때문에 시카고에 대한 정보를 알 수 없습니다. 하지만 일반적으로 시카고는 미국 내에 위치해 있습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이기 때문에 미세먼지 정보를 알 수 없습니다. 하지만 일반적으로 미세먼지는 건강에 매우 중요하기 때문에 외출 시 마스크 착용과 예방수칙을 준수하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='/aiffel/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=eos_token_id,\n",
    "    pad_token_id=eos_token_id, \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "               '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca1fa14",
   "metadata": {},
   "source": [
    "## 정성적 평가\n",
    "\n",
    "전체적으로 인공지능 챗봇에 알맞은 대답을 하고 있다는 생각이 든다.\n",
    "\n",
    "내용을 분석해보자면\n",
    "\n",
    "1. 불고기에 대한 내용은 고기를 먹을 수 있는지에 대한 답변이 나오는 것은 자연스럽지 않다고 생각한다.\n",
    "2. 년도를 묻는 질문에 적절하지 않은 대답이다.\n",
    "3. 포괄적이지만 틀린 내용은 아니다.\n",
    "4. 미세먼지 정보를 모르는 상황에서 적절한 대답이다.\n",
    "\n",
    "eos token과 pad token, early stopping을 추가하여 쓸모없는 내용이 나오는 부분을 나오지 않도록 수정하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae9880",
   "metadata": {},
   "source": [
    "## ChatGPT 4o가 생성한 reference와 ROUGE 스코어 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e689edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 AI 어시스턴트이기 때문에 고기를 먹을 수는 없습니다. 하지만 일반적으로 불고기는 고기와 함께 먹는 경우가 많으니까 맛있게 드세요!\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨은 41대 부통령직을 수행했습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어?\n",
      "\n",
      "### Response(응답):'시카고 오 헤어 국제공항은 미국 캘리포니아주 샌프란시스코에 위치해 있습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이기 때문에 미세먼지 정보를 알 수 없습니다. 하지만 일반적으로 미세먼지는 호흡기 건강에 매우 중요한 역할을 하기 때문에, 외출 시 반드시 마스크를 착용하고 실내에서 대기오염을 줄이는 것이 좋습니다.\n",
      "\n",
      "Extracting generated responses...\n",
      "\n",
      "✨ ROUGE 스코어 함수를 호출하여 모델 성능 평가를 시작합니다...\n",
      "\n",
      "\n",
      "--- 💯 개별 샘플 ROUGE 스코어 ---\n",
      "\n",
      "📜 샘플 1:\n",
      "  ROUGE 점수:\n",
      "    ROUGE1: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGE2: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGEL: P=0.0000, R=0.0000, F1=0.0000\n",
      "\n",
      "📜 샘플 2:\n",
      "  ROUGE 점수:\n",
      "    ROUGE1: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGE2: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGEL: P=0.0000, R=0.0000, F1=0.0000\n",
      "\n",
      "📜 샘플 3:\n",
      "  ROUGE 점수:\n",
      "    ROUGE1: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGE2: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGEL: P=0.0000, R=0.0000, F1=0.0000\n",
      "\n",
      "📜 샘플 4:\n",
      "  ROUGE 점수:\n",
      "    ROUGE1: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGE2: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGEL: P=0.0000, R=0.0000, F1=0.0000\n",
      "\n",
      "\n",
      "--- 📉 전체 샘플 평균 ROUGE 스코어 ---\n",
      "  평균 ROUGE1: P=0.0000, R=0.0000, F1=0.0000\n",
      "  평균 ROUGE2: P=0.0000, R=0.0000, F1=0.0000\n",
      "  평균 ROUGEL: P=0.0000, R=0.0000, F1=0.0000\n",
      "\n",
      "✅ ROUGE 점수 계산이 완료되었습니다!\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='/aiffel/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=eos_token_id,\n",
    "    pad_token_id=eos_token_id, \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "               '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))\n",
    "\n",
    "# --- 👇 ROUGE 함수 호출을 위한 추가 코드 ---\n",
    "\n",
    "# 1. 모델이 생성한 \"응답\" 부분만 추출하기\n",
    "list_generated_responses = []\n",
    "response_marker = PROMPT_DICT[\"prompt_input\"].split(\"{prompt}\")[1].split(\"### Response(응답):\")[0] + \"### Response(응답):\" # \"### Response(응답):\" 마커\n",
    "\n",
    "# 원본 질문 (참조 텍스트와 매칭하기 위함)\n",
    "list_prompt_original = ['불고기용 고기 한우에요?',\n",
    "                       '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "                       '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "                       '오늘 미세먼지 어때?']\n",
    "\n",
    "print(\"\\nExtracting generated responses...\")\n",
    "for i, single_result_list in enumerate(list_result):\n",
    "    full_generated_text = single_result_list[0]['generated_text']\n",
    "    \n",
    "    # \"### Response(응답):\" 마커 이후의 텍스트를 추출\n",
    "    # rfind를 사용하여 프롬프트와 응답 사이에 마커가 여러 번 나오는 경우, 마지막 마커를 기준으로 함\n",
    "    marker_position = full_generated_text.rfind(response_marker)\n",
    "    \n",
    "    if marker_position != -1:\n",
    "        # 마커 다음부터 텍스트 추출\n",
    "        response_only = full_generated_text[marker_position + len(response_marker):].strip()\n",
    "    else:\n",
    "        # 마커를 찾지 못한 경우, 포맷팅된 프롬프트(list_prompt[i]) 이후의 텍스트를 가져오려는 시도\n",
    "        # 이 방법은 모델이 프롬프트를 그대로 반복하지 않으면 정확하지 않을 수 있습니다.\n",
    "        try:\n",
    "            response_only = full_generated_text.split(list_prompt[i])[1].strip()\n",
    "        except IndexError:\n",
    "            print(f\"⚠️ Warning: 응답 마커 및 프롬프트 분리를 찾지 못했습니다. 샘플 {i}는 전체 텍스트를 사용합니다.\")\n",
    "            response_only = full_generated_text # 최후의 수단 (개선 필요)\n",
    "\n",
    "    # eos_token (예: '\\n' 또는 tokenizer.eos_token) 정리\n",
    "    # generation_args의 eos_token_id가 375 ('\\n')로 되어 있으므로, 이를 기준으로 처리\n",
    "    # tokenizer.eos_token (예: '</s>')도 함께 고려하면 좋습니다.\n",
    "    if tokenizer.eos_token: # tokenizer 변수가 사용 가능해야 합니다.\n",
    "         response_only = response_only.replace(tokenizer.eos_token, \"\")\n",
    "    \n",
    "    # eos_token_id=375가 '\\n'이라고 가정하고, 첫 줄바꿈 이전 텍스트만 사용하거나 불필요한 줄바꿈 제거\n",
    "    response_only = response_only.split('\\n')[0].strip()\n",
    "    \n",
    "    list_generated_responses.append(response_only)\n",
    "    # print(f\"  Q: {list_prompt_original[i]}\") # 디버깅용\n",
    "    # print(f\"  Extracted A: {response_only}\") # 디버깅용\n",
    "\n",
    "# 2. 참조 (정답) 텍스트 준비\n",
    "#    list_prompt_original의 각 질문에 대한 이상적인 답변을 작성합니다.\n",
    "#    이 목록은 모델의 답변과 비교될 \"정답지\" 역할을 합니다.\n",
    "list_references = [\n",
    "    \"정확히 알 수 없습니다. 판매자에게 고기의 원산지 및 품종(예: 한우, 수입육 등)을 확인하세요. 대부분 포장지에 표시돼 있습니다.\",\n",
    "    \"리처드 닉슨은 1953년부터 1961년까지 제43대 미국 부통령이었습니다.\",\n",
    "    \"미국 일리노이주 시카고 시 북서쪽, 시 외곽의 쿡 카운티에 위치해 있습니다.\",\n",
    "    \"사용자의 지역 정보가 없으므로 정확한 수치를 알 수 없습니다. 포털 사이트나 환경부 ‘에어코리아’에서 실시간 확인 가능합니다.\"\n",
    "]\n",
    "\n",
    "# 생성된 응답과 참조 텍스트의 개수가 같은지 확인\n",
    "if len(list_generated_responses) != len(list_references):\n",
    "    print(f\"⚠️ 경고: 생성된 응답의 수({len(list_generated_responses)})와 참조 텍스트의 수({len(list_references)})가 다릅니다.\")\n",
    "    print(\"    ROUGE 스코어 계산을 위해 참조 텍스트 목록을 확인하고 조정해주세요.\")\n",
    "else:\n",
    "    # 3. 이전에 정의한 ROUGE 스코어 함수 호출\n",
    "    #    (calculate_and_print_rouge_scores 함수가 이전에 노트북에 정의되어 있어야 합니다)\n",
    "    print(\"\\n✨ ROUGE 스코어 함수를 호출하여 모델 성능 평가를 시작합니다...\")\n",
    "    \n",
    "    # calculate_and_print_rouge_scores 함수가 정의되어 있다고 가정하고 호출\n",
    "    # from rouge_score import rouge_scorer # 함수 내에 있으므로 여기서 다시 임포트할 필요는 없음\n",
    "    \n",
    "    average_rouge_scores = calculate_and_print_rouge_scores(\n",
    "        generated_texts=list_generated_responses,\n",
    "        reference_texts=list_references,\n",
    "        use_stemmer=False,  # 한국어의 경우 True로 설정하고 적절한 환경 구성 필요\n",
    "        print_individual_scores=True # 각 샘플별 점수 출력 여부\n",
    "    )\n",
    "\n",
    "    if average_rouge_scores:\n",
    "        print(\"\\n✅ ROUGE 점수 계산이 완료되었습니다!\")\n",
    "        # print(\"\\n반환된 평균 점수 딕셔너리 (F1 기준):\", average_rouge_scores) # 상세 결과 확인용\n",
    "    else:\n",
    "        print(\"❌ ROUGE 점수 계산에 실패했거나 결과가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953d1e6",
   "metadata": {},
   "source": [
    "## ROUGE 스코어와 비교 평가\n",
    "각 질문들에 대해 ChatGPT 4o가 예측한 문자열과 비교하여 ROUGE 평가를 진행하였다.\n",
    "\n",
    "ChatGPT 4o가 생성해 낸 답변은 부통령 정보가 약간 틀리다는 점을 제외하면 올바른 대답이였다.\n",
    "\n",
    "ROUGE 점수는 모두 0으로, 점수 값을 전혀 확인할 수 없었다.\n",
    "\n",
    "ROUGE 점수로는 두 대답 간의 의미적 유사도를 측정하지 못하고, 단순히 같은 n-gram이 존재하는지를 위주로 확인하기 때문이다.\n",
    "\n",
    "따라서 BERTScore를 이용하여 다시 평가하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d65cae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "     |████████████████████████████████| 61 kB 4.2 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from bert-score) (4.28.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from bert-score) (1.3.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from bert-score) (3.4.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.9/site-packages (from bert-score) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from bert-score) (2.26.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from bert-score) (1.21.4)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from bert-score) (1.12.1)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.9/site-packages (from bert-score) (4.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.9->bert-score) (3.0.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (4.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.15.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.13.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->bert-score) (8.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->bert-score) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->bert-score) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->bert-score) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->bert-score) (2.0.8)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=3.0.0->bert-score) (2021.11.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24c40536",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563b1bc5fc574dccbb4a81b4281d62b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67db75f144eb488d81fc3bb7f5cdf00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.09 seconds, 44.25 sentences/sec\n",
      "\n",
      "🔹 예제 1\n",
      "  📝 질문: 불고기용 고기 한우에요?\n",
      "  🤖 응답: '저는 AI 어시스턴트이기 때문에 고기를 먹을 수는 없습니다. 하지만 일반적으로 불고기는 고기와 함께 먹는 경우가 많으니까 맛있게 드세요!\n",
      "  ✅ 정답: 정확히 알 수 없습니다. 판매자에게 고기의 원산지 및 품종(예: 한우, 수입육 등)을 확인하세요. 대부분 포장지에 표시돼 있습니다.\n",
      "  📌 BERTScore - Precision: 0.5595, Recall: 0.5766, F1: 0.5679\n",
      "\n",
      "🔹 예제 2\n",
      "  📝 질문: 리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "  🤖 응답: '리처드 닉슨은 41대 부통령직을 수행했습니다.\n",
      "  ✅ 정답: 리처드 닉슨은 1953년부터 1961년까지 제43대 미국 부통령이었습니다.\n",
      "  📌 BERTScore - Precision: 0.7447, Recall: 0.6455, F1: 0.6916\n",
      "\n",
      "🔹 예제 3\n",
      "  📝 질문: 시카고 오헤어 국제공항은 어디에 있어?\n",
      "  🤖 응답: '시카고 오 헤어 국제공항은 미국 캘리포니아주 샌프란시스코에 위치해 있습니다.\n",
      "  ✅ 정답: 미국 일리노이주 시카고 시 북서쪽, 시 외곽의 쿡 카운티에 위치해 있습니다.\n",
      "  📌 BERTScore - Precision: 0.7028, Recall: 0.6267, F1: 0.6626\n",
      "\n",
      "🔹 예제 4\n",
      "  📝 질문: 오늘 미세먼지 어때?\n",
      "  🤖 응답: '저는 인공지능 챗봇이기 때문에 미세먼지 정보를 알 수 없습니다. 하지만 일반적으로 미세먼지는 호흡기 건강에 매우 중요한 역할을 하기 때문에, 외출 시 반드시 마스크를 착용하고 실내에서 대기오염을 줄이는 것이 좋습니다.\n",
      "  ✅ 정답: 사용자의 지역 정보가 없으므로 정확한 수치를 알 수 없습니다. 포털 사이트나 환경부 ‘에어코리아’에서 실시간 확인 가능합니다.\n",
      "  📌 BERTScore - Precision: 0.5723, Recall: 0.6261, F1: 0.5980\n",
      "\n",
      "📊 BERTScore F1 평균: 0.6300\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# BERTScore 계산 (기본 모델: roberta-large, 한국어는 아래 참고)\n",
    "P, R, F1 = score(list_generated_responses, list_references, model_type=\"klue/roberta-base\", num_layers=12, verbose=True)\n",
    "\n",
    "# 각 문장별 점수 출력\n",
    "for i, (p, r, f1) in enumerate(zip(P, R, F1)):\n",
    "    print(f\"\\n🔹 예제 {i+1}\")\n",
    "    print(f\"  📝 질문: {list_prompt_original[i]}\")\n",
    "    print(f\"  🤖 응답: {list_generated_responses[i]}\")\n",
    "    print(f\"  ✅ 정답: {list_references[i]}\")\n",
    "    print(f\"  📌 BERTScore - Precision: {p:.4f}, Recall: {r:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "# 평균 F1 출력\n",
    "print(f\"\\n📊 BERTScore F1 평균: {F1.mean().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac18e1c7",
   "metadata": {},
   "source": [
    "## BERTScore 평가\n",
    "각 질문들에 대해 ChatGPT 4o가 예측한 문자열과 비교하여 BERTScore 평가를 진행하였다.\n",
    "\n",
    "확실히 ROUGE 점수에 비해 의미있는 값을 확인할 수 있었다.\n",
    "\n",
    "각 점수가 높은 점수인지는 아래 모델들과 비교하여 분석하겠다.\n",
    "\n",
    "특징적으로 2, 3번 질문에 대한 대답이 점수가 좋게 나왔는데, 1, 4번의 경우 정확한 정보를 전달하지 못하다 보니 내용이 다른 부분이 많아졌고, 2, 3번의 경우 맞든 틀리든 비슷한 정보를 전달하려는 시도가 있었기에 점수가 높게 나오지 않았나 하는 생각이 들었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e94f2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ebb8f6",
   "metadata": {},
   "source": [
    "## RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db8802ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# colossalai_ChatGPT_230319 라이브러리의 루트 경로를 sys.path에 추가\n",
    "library_root_path = '/aiffel/KoChatGPT/colossalai_ChatGPT_230319'\n",
    "\n",
    "if library_root_path not in sys.path:\n",
    "    sys.path.insert(0, library_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60349b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4119fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51fd5efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe83fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': '애플은 리사를 어떻게 처리했어', 'chosen': '애플이 누구인지 명확히 알 수 없어서, 리사가 누구인지와 어떤 상황에서 처리되었는지에 대한 추가적인 정보가 필요합니다. 따라서, 보다 정확한 답변을 제공할 수 없습니다.', 'rejected': '애플은 리사를 위해 고객 서비스 부서에서 고객 다양한 컴퓨터 관련 문제에 대해 응답하는 데 필요한 모든 지원을 제공했습니다. 사용자가 하드웨어 문제를 경험할 때, 전문가들은 필요한 수리(수리, 추가 부품 제공, 소프트웨어 업그레이드 등)을 제공해 드릴 수 있습니다. 또한, 사용자가 사용 방법 문제나 기타 문제를 경험할 때, 대화 상대로 사용자를 지원할 수 있는 전문 고객 서비스 직원들이 사용자에게 상담하고 도움을 주는 데 도움이 될 수 있는 정보를 제공합니다. 또한, 인터넷에서 제공되는 정보를 통해 문제를 해결하거나 고객 서비스 웹 사이트를 통해 자신의 문제를 진단할 수 있도록 하는 등 다양한 방법으로 리사를 처리해 왔습니다.'}\n"
     ]
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffc04c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은?', 'chosen': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은 류승완의 사무실입니다.', 'rejected': '대구 영화사옥'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9719c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1407.22it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1405.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffb2524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa4ea55f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Train step of epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:01<04:39,  1.12s/it]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:01<04:39,  1.12s/it, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:02<04:14,  1.03s/it, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:02<04:14,  1.03s/it, loss=0.403]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:03<04:07,  1.00s/it, loss=0.403]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:03<04:07,  1.00s/it, loss=0.464]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:04<04:03,  1.01it/s, loss=0.464]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:04<04:03,  1.01it/s, loss=0.55] \u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<04:00,  1.02it/s, loss=0.55]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:05<04:00,  1.02it/s, loss=0.318]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:59,  1.02it/s, loss=0.318]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:06<03:59,  1.02it/s, loss=1.06] \u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:58,  1.02it/s, loss=1.06]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:58,  1.02it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:07<03:58,  1.02it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:07<03:58,  1.02it/s, loss=2.29] \u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:08<03:57,  1.01it/s, loss=2.29]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:08<03:57,  1.01it/s, loss=0.296]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:09<03:57,  1.01it/s, loss=0.296]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:09<03:57,  1.01it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:10<03:57,  1.01it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:10<03:57,  1.01it/s, loss=0.406]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:11<03:57,  1.00it/s, loss=0.406]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:11<03:57,  1.00it/s, loss=0.553]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:12<03:57,  1.00s/it, loss=0.553]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:12<03:57,  1.00s/it, loss=0.245]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:13<03:56,  1.00s/it, loss=0.245]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:13<03:56,  1.00s/it, loss=0.827]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:14<03:56,  1.01s/it, loss=0.827]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:15<03:56,  1.01s/it, loss=0.623]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:15<03:56,  1.01s/it, loss=0.623]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:16<03:56,  1.01s/it, loss=1.23] \u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:17<03:55,  1.01s/it, loss=1.23]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:17<03:55,  1.01s/it, loss=0.673]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:18<03:53,  1.01s/it, loss=0.673]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:18<03:53,  1.01s/it, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:19<03:52,  1.01s/it, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:19<03:52,  1.01s/it, loss=0.726]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:20<03:50,  1.00s/it, loss=0.726]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:20<03:50,  1.00s/it, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:20<03:48,  1.00it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:21<03:48,  1.00it/s, loss=0.584]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:21<03:46,  1.01it/s, loss=0.584]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:22<03:46,  1.01it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:22<03:44,  1.01it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:22<03:44,  1.01it/s, loss=0.879]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:23<03:42,  1.02it/s, loss=0.879]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:23<03:42,  1.02it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:24<03:40,  1.02it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:24<03:40,  1.02it/s, loss=0.477]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:25<03:38,  1.03it/s, loss=0.477]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:25<03:38,  1.03it/s, loss=0.654]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:26<03:36,  1.03it/s, loss=0.654]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:26<03:36,  1.03it/s, loss=0.802]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:27<03:34,  1.04it/s, loss=0.802]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:27<03:34,  1.04it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:28<03:32,  1.04it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:28<03:32,  1.04it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:29<03:30,  1.04it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:29<03:30,  1.04it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:30<03:28,  1.05it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:30<03:28,  1.05it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:31<03:27,  1.05it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:31<03:27,  1.05it/s, loss=0.753]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:32<03:25,  1.06it/s, loss=0.753]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:32<03:25,  1.06it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:33<03:23,  1.06it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:33<03:23,  1.06it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:34<03:22,  1.06it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:34<03:22,  1.06it/s, loss=0.885]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:35<03:20,  1.07it/s, loss=0.885]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:35<03:20,  1.07it/s, loss=1.03] \u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:36<03:19,  1.07it/s, loss=1.03]\u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:36<03:19,  1.07it/s, loss=0.799]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:37<03:18,  1.07it/s, loss=0.799]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:37<03:18,  1.07it/s, loss=0.752]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:38<03:16,  1.07it/s, loss=0.752]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:38<03:16,  1.07it/s, loss=0.978]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:39<03:15,  1.07it/s, loss=0.978]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:39<03:15,  1.07it/s, loss=0.532]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:39<03:14,  1.08it/s, loss=0.532]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:39<03:14,  1.08it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:40<03:13,  1.08it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:40<03:13,  1.08it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:41<03:11,  1.08it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:41<03:11,  1.08it/s, loss=0.727]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:42<03:10,  1.08it/s, loss=0.727]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:42<03:10,  1.08it/s, loss=0.808]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:43<03:09,  1.08it/s, loss=0.808]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:43<03:09,  1.08it/s, loss=0.58] \u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:44<03:08,  1.08it/s, loss=0.58]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:44<03:08,  1.08it/s, loss=0.52]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:45<03:07,  1.08it/s, loss=0.52]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:45<03:07,  1.08it/s, loss=0.696]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:46<03:06,  1.08it/s, loss=0.696]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:46<03:06,  1.08it/s, loss=0.726]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:47<03:05,  1.09it/s, loss=0.726]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:47<03:05,  1.09it/s, loss=0.627]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:48<03:03,  1.09it/s, loss=0.627]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:48<03:03,  1.09it/s, loss=0.757]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:49<03:02,  1.09it/s, loss=0.757]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:49<03:02,  1.09it/s, loss=0.447]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:50<03:01,  1.09it/s, loss=0.447]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:50<03:01,  1.09it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:50<03:00,  1.09it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:51<03:00,  1.09it/s, loss=0.442]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:51<03:00,  1.09it/s, loss=0.442]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:51<03:00,  1.09it/s, loss=0.401]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:52<02:58,  1.09it/s, loss=0.401]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:52<02:58,  1.09it/s, loss=0.483]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:53<02:57,  1.09it/s, loss=0.483]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:53<02:57,  1.09it/s, loss=0.531]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:54<02:56,  1.09it/s, loss=0.531]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:54<02:56,  1.09it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:55<02:55,  1.09it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:55<02:55,  1.09it/s, loss=0.436]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:56<02:54,  1.09it/s, loss=0.436]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:56<02:54,  1.09it/s, loss=0.62] \u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:57<02:53,  1.09it/s, loss=0.62]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:57<02:53,  1.09it/s, loss=0.269]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:58<02:52,  1.09it/s, loss=0.269]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:58<02:52,  1.09it/s, loss=1.15] \u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:59<02:51,  1.09it/s, loss=1.15]\u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:59<02:51,  1.09it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [01:00<02:50,  1.09it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [01:00<02:50,  1.09it/s, loss=0.98] \u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [01:01<02:50,  1.09it/s, loss=0.98]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [01:01<02:50,  1.09it/s, loss=0.274]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [01:01<02:49,  1.09it/s, loss=0.274]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [01:01<02:49,  1.09it/s, loss=0.746]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [01:02<02:48,  1.09it/s, loss=0.746]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [01:02<02:48,  1.09it/s, loss=0.177]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [01:03<02:47,  1.09it/s, loss=0.177]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [01:03<02:47,  1.09it/s, loss=0.867]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [01:04<02:47,  1.09it/s, loss=0.867]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [01:04<02:47,  1.09it/s, loss=0.398]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:05<02:46,  1.09it/s, loss=0.398]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:05<02:46,  1.09it/s, loss=0.806]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:06<02:45,  1.09it/s, loss=0.806]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:06<02:45,  1.09it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:07<02:44,  1.09it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:07<02:44,  1.09it/s, loss=0.587]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:08<02:43,  1.09it/s, loss=0.587]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:08<02:43,  1.09it/s, loss=0.849]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:09<02:42,  1.09it/s, loss=0.849]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:09<02:42,  1.09it/s, loss=0.829]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:10<02:42,  1.09it/s, loss=0.829]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:10<02:42,  1.09it/s, loss=0.583]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:11<02:41,  1.08it/s, loss=0.583]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:11<02:41,  1.08it/s, loss=0.713]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:12<02:40,  1.08it/s, loss=0.713]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:12<02:40,  1.08it/s, loss=0.72] \u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:13<02:39,  1.08it/s, loss=0.72]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:13<02:39,  1.08it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:13<02:38,  1.08it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:13<02:38,  1.08it/s, loss=0.602]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:14<02:38,  1.08it/s, loss=0.602]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:14<02:38,  1.08it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:15<02:37,  1.08it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:15<02:37,  1.08it/s, loss=0.718]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:16<02:36,  1.08it/s, loss=0.718]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:16<02:36,  1.08it/s, loss=0.349]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:17<02:35,  1.08it/s, loss=0.349]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:17<02:35,  1.08it/s, loss=0.783]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:18<02:34,  1.08it/s, loss=0.783]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:18<02:34,  1.08it/s, loss=0.533]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:19<02:34,  1.08it/s, loss=0.533]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:19<02:34,  1.08it/s, loss=0.654]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:20<02:33,  1.08it/s, loss=0.654]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:20<02:33,  1.08it/s, loss=0.778]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:21<02:32,  1.07it/s, loss=0.778]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:21<02:32,  1.07it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:22<02:32,  1.07it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:22<02:32,  1.07it/s, loss=0.468]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:23<02:30,  1.07it/s, loss=0.468]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:23<02:30,  1.07it/s, loss=1.06] \u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:24<02:30,  1.07it/s, loss=1.06]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:24<02:30,  1.07it/s, loss=0.857]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:25<02:29,  1.07it/s, loss=0.857]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:25<02:29,  1.07it/s, loss=0.726]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:26<02:28,  1.07it/s, loss=0.726]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:26<02:28,  1.07it/s, loss=0.664]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:27<02:27,  1.07it/s, loss=0.664]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:27<02:27,  1.07it/s, loss=0.627]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:27<02:26,  1.07it/s, loss=0.627]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:27<02:26,  1.07it/s, loss=0.821]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:28<02:26,  1.07it/s, loss=0.821]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:28<02:26,  1.07it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:29<02:25,  1.07it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:29<02:25,  1.07it/s, loss=0.581]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:30<02:24,  1.06it/s, loss=0.581]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:30<02:24,  1.06it/s, loss=0.729]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:31<02:24,  1.06it/s, loss=0.729]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:31<02:24,  1.06it/s, loss=0.753]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:32<02:23,  1.06it/s, loss=0.753]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:32<02:23,  1.06it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:33<02:22,  1.06it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:33<02:22,  1.06it/s, loss=0.617]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:34<02:21,  1.06it/s, loss=0.617]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:34<02:21,  1.06it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:35<02:20,  1.06it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:35<02:20,  1.06it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:36<02:19,  1.06it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:36<02:19,  1.06it/s, loss=0.719]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:37<02:19,  1.06it/s, loss=0.719]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:37<02:19,  1.06it/s, loss=0.734]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:38<02:18,  1.06it/s, loss=0.734]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:38<02:18,  1.06it/s, loss=0.753]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:39<02:17,  1.06it/s, loss=0.753]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:39<02:17,  1.06it/s, loss=0.64] \u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:40<02:16,  1.06it/s, loss=0.64]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:40<02:16,  1.06it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:41<02:15,  1.06it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:41<02:15,  1.06it/s, loss=0.701]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:42<02:14,  1.06it/s, loss=0.701]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:42<02:14,  1.06it/s, loss=0.635]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:43<02:13,  1.06it/s, loss=0.635]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:43<02:13,  1.06it/s, loss=0.685]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:44<02:12,  1.06it/s, loss=0.685]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:44<02:12,  1.06it/s, loss=0.713]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:44<02:11,  1.06it/s, loss=0.713]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:44<02:11,  1.06it/s, loss=0.643]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:45<02:10,  1.06it/s, loss=0.643]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:45<02:10,  1.06it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:46<02:09,  1.06it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:46<02:09,  1.06it/s, loss=0.663]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:47<02:08,  1.06it/s, loss=0.663]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:47<02:08,  1.06it/s, loss=0.749]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:48<02:07,  1.06it/s, loss=0.749]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:48<02:07,  1.06it/s, loss=0.684]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:49<02:06,  1.06it/s, loss=0.684]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:49<02:06,  1.06it/s, loss=0.643]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:50<02:05,  1.06it/s, loss=0.643]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:50<02:05,  1.06it/s, loss=0.616]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:51<02:04,  1.06it/s, loss=0.616]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:51<02:04,  1.06it/s, loss=0.578]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:52<02:03,  1.06it/s, loss=0.578]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:52<02:03,  1.06it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:53<02:02,  1.06it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:53<02:02,  1.06it/s, loss=0.905]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:54<02:01,  1.06it/s, loss=0.905]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:54<02:01,  1.06it/s, loss=0.773]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:55<02:00,  1.06it/s, loss=0.773]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:55<02:00,  1.06it/s, loss=0.648]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:56<01:59,  1.06it/s, loss=0.648]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:56<01:59,  1.06it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:57<01:58,  1.06it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:57<01:58,  1.06it/s, loss=0.668]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:58<01:57,  1.06it/s, loss=0.668]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:58<01:57,  1.06it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:59<01:56,  1.06it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:59<01:56,  1.06it/s, loss=0.674]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [02:00<01:55,  1.06it/s, loss=0.674]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [02:00<01:55,  1.06it/s, loss=0.601]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [02:00<01:54,  1.07it/s, loss=0.601]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [02:01<01:54,  1.07it/s, loss=0.588]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [02:01<01:53,  1.07it/s, loss=0.588]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [02:01<01:53,  1.07it/s, loss=0.654]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [02:02<01:52,  1.07it/s, loss=0.654]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [02:02<01:52,  1.07it/s, loss=0.659]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [02:03<01:51,  1.07it/s, loss=0.659]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [02:03<01:51,  1.07it/s, loss=0.845]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [02:04<01:50,  1.07it/s, loss=0.845]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [02:04<01:50,  1.07it/s, loss=0.605]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [02:05<01:49,  1.07it/s, loss=0.605]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [02:05<01:49,  1.07it/s, loss=0.773]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [02:06<01:48,  1.07it/s, loss=0.773]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [02:06<01:48,  1.07it/s, loss=0.752]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [02:07<01:47,  1.07it/s, loss=0.752]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [02:07<01:47,  1.07it/s, loss=0.741]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [02:08<01:46,  1.07it/s, loss=0.741]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [02:08<01:46,  1.07it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:09<01:45,  1.07it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:09<01:45,  1.07it/s, loss=0.529]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:10<01:44,  1.07it/s, loss=0.529]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:10<01:44,  1.07it/s, loss=0.604]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:11<01:43,  1.07it/s, loss=0.604]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:11<01:43,  1.07it/s, loss=0.538]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:12<01:42,  1.08it/s, loss=0.538]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:12<01:42,  1.08it/s, loss=0.501]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:13<01:41,  1.08it/s, loss=0.501]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:13<01:41,  1.08it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:14<01:40,  1.08it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:14<01:40,  1.08it/s, loss=0.779]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:14<01:39,  1.08it/s, loss=0.779]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:14<01:39,  1.08it/s, loss=0.518]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:15<01:38,  1.08it/s, loss=0.518]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:15<01:38,  1.08it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:16<01:37,  1.08it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:16<01:37,  1.08it/s, loss=0.617]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:17<01:36,  1.08it/s, loss=0.617]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:17<01:36,  1.08it/s, loss=0.631]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:18<01:35,  1.08it/s, loss=0.631]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:18<01:35,  1.08it/s, loss=0.323]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:19<01:34,  1.08it/s, loss=0.323]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:19<01:34,  1.08it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:20<01:33,  1.08it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:20<01:33,  1.08it/s, loss=0.657]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:21<01:32,  1.08it/s, loss=0.657]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:21<01:32,  1.08it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:22<01:31,  1.08it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:22<01:31,  1.08it/s, loss=0.24] \u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:23<01:30,  1.08it/s, loss=0.24]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:23<01:30,  1.08it/s, loss=0.523]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:24<01:29,  1.08it/s, loss=0.523]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:24<01:29,  1.08it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:25<01:29,  1.08it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:25<01:29,  1.08it/s, loss=1.33] \u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:26<01:28,  1.08it/s, loss=1.33]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:26<01:28,  1.08it/s, loss=0.808]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:27<01:27,  1.08it/s, loss=0.808]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:27<01:27,  1.08it/s, loss=0.404]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:27<01:26,  1.08it/s, loss=0.404]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:27<01:26,  1.08it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:28<01:25,  1.08it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:28<01:25,  1.08it/s, loss=0.696]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:29<01:24,  1.08it/s, loss=0.696]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:29<01:24,  1.08it/s, loss=0.741]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:30<01:23,  1.08it/s, loss=0.741]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:30<01:23,  1.08it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:31<01:22,  1.08it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:31<01:22,  1.08it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:32<01:21,  1.08it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:32<01:21,  1.08it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:33<01:20,  1.08it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:33<01:20,  1.08it/s, loss=0.434]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:34<01:19,  1.08it/s, loss=0.434]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:34<01:19,  1.08it/s, loss=0.718]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:35<01:18,  1.08it/s, loss=0.718]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:35<01:18,  1.08it/s, loss=0.929]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:36<01:17,  1.08it/s, loss=0.929]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:36<01:17,  1.08it/s, loss=0.427]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:37<01:16,  1.08it/s, loss=0.427]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:37<01:16,  1.08it/s, loss=0.387]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:38<01:16,  1.08it/s, loss=0.387]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:38<01:16,  1.08it/s, loss=0.536]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:39<01:15,  1.08it/s, loss=0.536]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:39<01:15,  1.08it/s, loss=0.416]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:39<01:14,  1.08it/s, loss=0.416]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:40<01:14,  1.08it/s, loss=0.867]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:40<01:13,  1.08it/s, loss=0.867]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:40<01:13,  1.08it/s, loss=0.633]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:41<01:12,  1.08it/s, loss=0.633]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:41<01:12,  1.08it/s, loss=0.754]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:42<01:11,  1.08it/s, loss=0.754]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:42<01:11,  1.08it/s, loss=0.444]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:43<01:10,  1.08it/s, loss=0.444]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:43<01:10,  1.08it/s, loss=0.385]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:44<01:09,  1.07it/s, loss=0.385]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:44<01:09,  1.07it/s, loss=0.701]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:45<01:08,  1.08it/s, loss=0.701]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:45<01:08,  1.08it/s, loss=0.435]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:46<01:07,  1.07it/s, loss=0.435]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:46<01:07,  1.07it/s, loss=0.37] \u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:47<01:06,  1.08it/s, loss=0.37]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:47<01:06,  1.08it/s, loss=0.339]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:48<01:06,  1.07it/s, loss=0.339]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:48<01:06,  1.07it/s, loss=0.555]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:49<01:05,  1.07it/s, loss=0.555]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:49<01:05,  1.07it/s, loss=0.745]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:50<01:04,  1.07it/s, loss=0.745]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:50<01:04,  1.07it/s, loss=0.236]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:51<01:03,  1.07it/s, loss=0.236]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:51<01:03,  1.07it/s, loss=1]    \u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:52<01:02,  1.08it/s, loss=1]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:52<01:02,  1.08it/s, loss=1.45]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:53<01:01,  1.07it/s, loss=1.45]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:53<01:01,  1.07it/s, loss=0.905]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:53<01:00,  1.08it/s, loss=0.905]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:53<01:00,  1.08it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:54<00:59,  1.07it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:54<00:59,  1.07it/s, loss=0.418]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:55<00:58,  1.07it/s, loss=0.418]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:55<00:58,  1.07it/s, loss=0.386]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:56<00:57,  1.07it/s, loss=0.386]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:56<00:57,  1.07it/s, loss=0.668]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:57<00:56,  1.07it/s, loss=0.668]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:57<00:56,  1.07it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:58<00:55,  1.07it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:58<00:55,  1.07it/s, loss=0.466]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:59<00:54,  1.07it/s, loss=0.466]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:59<00:54,  1.07it/s, loss=0.362]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [03:00<00:53,  1.07it/s, loss=0.362]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [03:00<00:53,  1.07it/s, loss=0.502]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [03:01<00:53,  1.07it/s, loss=0.502]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [03:01<00:53,  1.07it/s, loss=0.762]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [03:02<00:52,  1.07it/s, loss=0.762]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [03:02<00:52,  1.07it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [03:03<00:51,  1.07it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [03:03<00:51,  1.07it/s, loss=0.455]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [03:04<00:50,  1.07it/s, loss=0.455]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [03:04<00:50,  1.07it/s, loss=0.937]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [03:05<00:49,  1.07it/s, loss=0.937]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [03:05<00:49,  1.07it/s, loss=0.668]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [03:06<00:48,  1.07it/s, loss=0.668]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [03:06<00:48,  1.07it/s, loss=0.608]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [03:06<00:47,  1.07it/s, loss=0.608]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [03:07<00:47,  1.07it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [03:07<00:46,  1.07it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [03:07<00:46,  1.07it/s, loss=0.457]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [03:08<00:45,  1.07it/s, loss=0.457]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [03:08<00:45,  1.07it/s, loss=0.474]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [03:09<00:44,  1.07it/s, loss=0.474]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [03:09<00:44,  1.07it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [03:10<00:43,  1.07it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [03:10<00:43,  1.07it/s, loss=0.589]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [03:11<00:42,  1.07it/s, loss=0.589]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [03:11<00:42,  1.07it/s, loss=0.521]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [03:12<00:41,  1.07it/s, loss=0.521]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [03:12<00:41,  1.07it/s, loss=0.555]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:13<00:41,  1.07it/s, loss=0.555]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:13<00:41,  1.07it/s, loss=0.766]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:14<00:40,  1.07it/s, loss=0.766]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:14<00:40,  1.07it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:15<00:39,  1.07it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:15<00:39,  1.07it/s, loss=0.667]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:16<00:38,  1.07it/s, loss=0.667]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:16<00:38,  1.07it/s, loss=0.667]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:17<00:37,  1.07it/s, loss=0.667]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:17<00:37,  1.07it/s, loss=0.681]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:18<00:36,  1.07it/s, loss=0.681]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:18<00:36,  1.07it/s, loss=0.449]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:19<00:35,  1.07it/s, loss=0.449]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:19<00:35,  1.07it/s, loss=0.565]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:20<00:34,  1.07it/s, loss=0.565]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:20<00:34,  1.07it/s, loss=0.352]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:20<00:33,  1.07it/s, loss=0.352]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:20<00:33,  1.07it/s, loss=1.2]  \u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:21<00:32,  1.07it/s, loss=1.2]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:21<00:32,  1.07it/s, loss=0.547]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:22<00:31,  1.07it/s, loss=0.547]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:22<00:31,  1.07it/s, loss=0.845]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:23<00:30,  1.07it/s, loss=0.845]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:23<00:30,  1.07it/s, loss=0.82] \u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:24<00:29,  1.07it/s, loss=0.82]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:24<00:29,  1.07it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:25<00:28,  1.07it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:25<00:28,  1.07it/s, loss=0.37] \u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:26<00:28,  1.07it/s, loss=0.37]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:26<00:28,  1.07it/s, loss=0.648]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:27<00:27,  1.07it/s, loss=0.648]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:27<00:27,  1.07it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:28<00:26,  1.07it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:28<00:26,  1.07it/s, loss=0.364]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:29<00:25,  1.07it/s, loss=0.364]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:29<00:25,  1.07it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:30<00:24,  1.07it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:30<00:24,  1.07it/s, loss=0.761]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:31<00:23,  1.07it/s, loss=0.761]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:31<00:23,  1.07it/s, loss=0.614]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:32<00:22,  1.07it/s, loss=0.614]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:32<00:22,  1.07it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:33<00:21,  1.07it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:33<00:21,  1.07it/s, loss=0.722]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:34<00:20,  1.07it/s, loss=0.722]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:34<00:20,  1.07it/s, loss=0.527]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:34<00:19,  1.07it/s, loss=0.527]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:35<00:19,  1.07it/s, loss=0.68] \u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:35<00:18,  1.07it/s, loss=0.68]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:35<00:18,  1.07it/s, loss=0.723]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:36<00:17,  1.07it/s, loss=0.723]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:36<00:17,  1.07it/s, loss=0.427]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:37<00:16,  1.07it/s, loss=0.427]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:37<00:16,  1.07it/s, loss=0.843]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:38<00:15,  1.07it/s, loss=0.843]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:38<00:15,  1.07it/s, loss=0.567]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:39<00:14,  1.07it/s, loss=0.567]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:39<00:14,  1.07it/s, loss=0.557]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:40<00:14,  1.07it/s, loss=0.557]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:40<00:14,  1.07it/s, loss=0.84] \u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:41<00:13,  1.07it/s, loss=0.84]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:41<00:13,  1.07it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:42<00:12,  1.07it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:42<00:12,  1.07it/s, loss=0.538]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:43<00:11,  1.07it/s, loss=0.538]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:43<00:11,  1.07it/s, loss=0.758]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:44<00:10,  1.07it/s, loss=0.758]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:44<00:10,  1.07it/s, loss=0.705]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:45<00:09,  1.07it/s, loss=0.705]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:45<00:09,  1.07it/s, loss=0.617]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:46<00:08,  1.07it/s, loss=0.617]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:46<00:08,  1.07it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:47<00:07,  1.07it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:47<00:07,  1.07it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:48<00:06,  1.07it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:48<00:06,  1.07it/s, loss=0.543]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:49<00:05,  1.07it/s, loss=0.543]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:49<00:05,  1.07it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:49<00:04,  1.07it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:49<00:04,  1.07it/s, loss=0.806]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:50<00:03,  1.07it/s, loss=0.806]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:50<00:03,  1.07it/s, loss=0.785]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:51<00:02,  1.07it/s, loss=0.785]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:51<00:02,  1.07it/s, loss=0.462]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:52<00:01,  1.07it/s, loss=0.462]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:52<00:01,  1.07it/s, loss=1.24] \u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:53<00:00,  1.07it/s, loss=1.24]\u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:53<00:00,  1.07it/s, loss=0.585]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:54<00:00,  1.07it/s, loss=0.585]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [04:10<00:00, 250.02s/it]0,  1.07it/s, loss=0.495]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [04:10<00:00,  1.00s/it, loss=0.62, dist_mean=0.258]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [04:10<00:00, 250.02s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('/aiffel/KoChatGPT/output_2_RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ebed5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 대한민국에서 가장 높은 산의 이름과 높이는 무엇인가요?\n",
      "reward score: -1.4\n"
     ]
    }
   ],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = '대한민국에서 가장 높은 산의 이름과 높이는 무엇인가요?'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70cecc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.\n",
      "reward score: -1.1\n"
     ]
    }
   ],
   "source": [
    "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b1da617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\n",
      "reward score: -1.0\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75d791fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
      "reward score: -1.0\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5b9b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05b0f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='/aiffel/KoChatGPT/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='/aiffel/KoChatGPT/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4781a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d8e3a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9eeb0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43f8ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e38d8ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:13<00:06,  6.63s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.000205]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.59it/s, actor_loss=0, critic_loss=0.000205]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.59it/s, actor_loss=0, critic_loss=0.118]   \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.69it/s, actor_loss=0, critic_loss=0.118]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.69it/s, actor_loss=0, critic_loss=0.00889]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.70it/s, actor_loss=0, critic_loss=0.00889]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:21<00:00,  7.24s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:13<00:06,  6.77s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.129, critic_loss=0.0242]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.75it/s, actor_loss=-.129, critic_loss=0.0242]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.75it/s, actor_loss=-.129, critic_loss=0.0712]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s, actor_loss=-.129, critic_loss=0.0712]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s, actor_loss=-.14, critic_loss=0.0461] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s, actor_loss=-.14, critic_loss=0.0461]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:21<00:00,  7.25s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.39s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.101, critic_loss=0.0135]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.79it/s, actor_loss=-.101, critic_loss=0.0135]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.79it/s, actor_loss=-.106, critic_loss=0.000762]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s, actor_loss=-.106, critic_loss=0.000762]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s, actor_loss=-.106, critic_loss=0.0103]  \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s, actor_loss=-.106, critic_loss=0.0103]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:20<00:00,  6.93s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.32s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.204, critic_loss=0.0634]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.78it/s, actor_loss=0.204, critic_loss=0.0634]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.78it/s, actor_loss=0.182, critic_loss=0.0258]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s, actor_loss=0.182, critic_loss=0.0258]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s, actor_loss=0.17, critic_loss=0.0106] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s, actor_loss=0.17, critic_loss=0.0106]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:20<00:00,  6.86s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.34s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0372, critic_loss=0.00101]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.74it/s, actor_loss=0.0372, critic_loss=0.00101]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.74it/s, actor_loss=0.0356, critic_loss=0.00361]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s, actor_loss=0.0356, critic_loss=0.00361]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s, actor_loss=0.0426, critic_loss=0.00663]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s, actor_loss=0.0426, critic_loss=0.00663]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:20<00:00,  6.98s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.43s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.115, critic_loss=0.0176]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.76it/s, actor_loss=-.115, critic_loss=0.0176]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.76it/s, actor_loss=-.103, critic_loss=0.0135]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s, actor_loss=-.103, critic_loss=0.0135]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s, actor_loss=-.115, critic_loss=0.00612]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s, actor_loss=-.115, critic_loss=0.00612]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:21<00:00,  7.02s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.37s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.00637, critic_loss=0.00312]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.77it/s, actor_loss=0.00637, critic_loss=0.00312]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.77it/s, actor_loss=-.0237, critic_loss=0.00181] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=-.0237, critic_loss=0.00181]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=0.000133, critic_loss=0.0074]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s, actor_loss=0.000133, critic_loss=0.0074]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:20<00:00,  6.95s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.27s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.127, critic_loss=0.012]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.77it/s, actor_loss=0.127, critic_loss=0.012]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.77it/s, actor_loss=0.0701, critic_loss=0.00327]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=0.0701, critic_loss=0.00327]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=0.115, critic_loss=0.0146]  \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s, actor_loss=0.115, critic_loss=0.0146]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:20<00:00,  6.85s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.62s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0152, critic_loss=0.000686]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.77it/s, actor_loss=-.0152, critic_loss=0.000686]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.77it/s, actor_loss=-.0118, critic_loss=0.0029]  \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s, actor_loss=-.0118, critic_loss=0.0029]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s, actor_loss=-.0123, critic_loss=0.00709]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s, actor_loss=-.0123, critic_loss=0.00709]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:19<00:00,  6.48s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.40s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0572, critic_loss=0.00496]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.77it/s, actor_loss=-.0572, critic_loss=0.00496]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.77it/s, actor_loss=-.0612, critic_loss=0.00302]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=-.0612, critic_loss=0.00302]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=-.0612, critic_loss=0.00106]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s, actor_loss=-.0612, critic_loss=0.00106]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:19<00:00,  6.40s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('/KoChatGPT/output_3_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2bba514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'제가 AI 어시스턴트이기 때문에 실제로 무엇을 먹는지에 대한 정보를 가지고 있지 않습니다. 하지만 일반적으로 한우고기는 쇠고기의 부드러움과 식감이 좋아 불고기의 한우를 선호하는 것으로 알고 있습니다. 하지만 일부 고기들은 다른 부위보다 더 크고 촉촉한 맛을 느낄 수 있는 경우도 많습니다. 하지만 보통 고기의 맛을 좋게 유지하기 위해서는 고기의 맛을 유지하면서도 적당히 섭취하는 것이 중요합니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨은 63대 부통령직을 수행하는 년도에 대한 추가 정보가 제공되지 않았기 때문에, 정확한 답변을 제공할 수 없습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'시카고 오헤어 국제공항은 캐나다의 영캐주 및 영국 지역에 위치하고 있습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'미세먼지 비상행동으로는 호흡 조절이 필요합니다. 호흡 조절에 도움을 주기 위해 호흡기 운동을 추천드립니다.\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1,\n",
    "                             eos_token_id=eos_token_id,\n",
    "                             pad_token_id=eos_token_id, \n",
    "                             early_stopping=True)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = []\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)\n",
    "    list_result.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad18f6",
   "metadata": {},
   "source": [
    "## PPO - 정성평가\n",
    "모두 기존의 결과보다 나쁜 응답이 나온 것을 확인할 수 있다.\n",
    "\n",
    "이를 통해 RM과 PPO를 사용할 때는 많은 데이터로 오래 학습시켜야 더 좋은 결과를 기대할 수 있다는 것을 알게 되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6edc474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting generated responses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8d3b68808143b0910abb55ec4ef4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a76f6e4e9d64ad5939133146098238b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.12 seconds, 32.45 sentences/sec\n",
      "\n",
      "🔹 예제 1\n",
      "  📝 질문: 불고기용 고기 한우에요?\n",
      "  🤖 응답: '제가 AI 어시스턴트이기 때문에 실제로 무엇을 먹는지에 대한 정보를 가지고 있지 않습니다. 하지만 일반적으로 한우고기는 쇠고기의 부드러움과 식감이 좋아 불고기의 한우를 선호하는 것으로 알고 있습니다. 하지만 일부 고기들은 다른 부위보다 더 크고 촉촉한 맛을 느낄 수 있는 경우도 많습니다. 하지만 보통 고기의 맛을 좋게 유지하기 위해서는 고기의 맛을 유지하면서도 적당히 섭취하는 것이 중요합니다.\n",
      "  ✅ 정답: 정확히 알 수 없습니다. 판매자에게 고기의 원산지 및 품종(예: 한우, 수입육 등)을 확인하세요. 대부분 포장지에 표시돼 있습니다.\n",
      "  📌 BERTScore - Precision: 0.5790, Recall: 0.6249, F1: 0.6011\n",
      "\n",
      "🔹 예제 2\n",
      "  📝 질문: 리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "  🤖 응답: '리처드 닉슨은 63대 부통령직을 수행하는 년도에 대한 추가 정보가 제공되지 않았기 때문에, 정확한 답변을 제공할 수 없습니다.\n",
      "  ✅ 정답: 리처드 닉슨은 1953년부터 1961년까지 제43대 미국 부통령이었습니다.\n",
      "  📌 BERTScore - Precision: 0.5383, Recall: 0.6378, F1: 0.5838\n",
      "\n",
      "🔹 예제 3\n",
      "  📝 질문: 시카고 오헤어 국제공항은 어디에 있어?\n",
      "  🤖 응답: '시카고 오헤어 국제공항은 캐나다의 영캐주 및 영국 지역에 위치하고 있습니다.\n",
      "  ✅ 정답: 미국 일리노이주 시카고 시 북서쪽, 시 외곽의 쿡 카운티에 위치해 있습니다.\n",
      "  📌 BERTScore - Precision: 0.6383, Recall: 0.6385, F1: 0.6384\n",
      "\n",
      "🔹 예제 4\n",
      "  📝 질문: 오늘 미세먼지 어때?\n",
      "  🤖 응답: '미세먼지 비상행동으로는 호흡 조절이 필요합니다. 호흡 조절에 도움을 주기 위해 호흡기 운동을 추천드립니다.\n",
      "  ✅ 정답: 사용자의 지역 정보가 없으므로 정확한 수치를 알 수 없습니다. 포털 사이트나 환경부 ‘에어코리아’에서 실시간 확인 가능합니다.\n",
      "  📌 BERTScore - Precision: 0.5134, Recall: 0.5131, F1: 0.5132\n",
      "\n",
      "📊 BERTScore F1 평균: 0.5841\n"
     ]
    }
   ],
   "source": [
    "# 1. 모델이 생성한 \"응답\" 부분만 추출하기\n",
    "list_generated_responses = []\n",
    "response_marker = PROMPT_DICT[\"prompt_input\"].split(\"{prompt}\")[1].split(\"### Response(응답):\")[0] + \"### Response(응답):\" # \"### Response(응답):\" 마커\n",
    "\n",
    "# 원본 질문 (참조 텍스트와 매칭하기 위함)\n",
    "list_prompt_original = ['불고기용 고기 한우에요?',\n",
    "                       '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "                       '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "                       '오늘 미세먼지 어때?']\n",
    "\n",
    "print(\"\\nExtracting generated responses...\")\n",
    "for i, full_generated_text in enumerate(list_result):\n",
    "    \n",
    "    # \"### Response(응답):\" 마커 이후의 텍스트를 추출\n",
    "    # rfind를 사용하여 프롬프트와 응답 사이에 마커가 여러 번 나오는 경우, 마지막 마커를 기준으로 함\n",
    "    marker_position = full_generated_text.rfind(response_marker)\n",
    "    \n",
    "    if marker_position != -1:\n",
    "        # 마커 다음부터 텍스트 추출\n",
    "        response_only = full_generated_text[marker_position + len(response_marker):].strip()\n",
    "    else:\n",
    "        # 마커를 찾지 못한 경우, 포맷팅된 프롬프트(list_prompt[i]) 이후의 텍스트를 가져오려는 시도\n",
    "        # 이 방법은 모델이 프롬프트를 그대로 반복하지 않으면 정확하지 않을 수 있습니다.\n",
    "        try:\n",
    "            response_only = full_generated_text.split(list_prompt[i])[1].strip()\n",
    "        except IndexError:\n",
    "            print(f\"⚠️ Warning: 응답 마커 및 프롬프트 분리를 찾지 못했습니다. 샘플 {i}는 전체 텍스트를 사용합니다.\")\n",
    "            response_only = full_generated_text # 최후의 수단 (개선 필요)\n",
    "\n",
    "    # eos_token (예: '\\n' 또는 tokenizer.eos_token) 정리\n",
    "    # generation_args의 eos_token_id가 375 ('\\n')로 되어 있으므로, 이를 기준으로 처리\n",
    "    # tokenizer.eos_token (예: '</s>')도 함께 고려하면 좋습니다.\n",
    "    if tokenizer.eos_token: # tokenizer 변수가 사용 가능해야 합니다.\n",
    "         response_only = response_only.replace(tokenizer.eos_token, \"\")\n",
    "    \n",
    "    # eos_token_id=375가 '\\n'이라고 가정하고, 첫 줄바꿈 이전 텍스트만 사용하거나 불필요한 줄바꿈 제거\n",
    "    response_only = response_only.split('\\n')[0].strip()\n",
    "    \n",
    "    list_generated_responses.append(response_only)\n",
    "    \n",
    "list_references = [\n",
    "    \"정확히 알 수 없습니다. 판매자에게 고기의 원산지 및 품종(예: 한우, 수입육 등)을 확인하세요. 대부분 포장지에 표시돼 있습니다.\",\n",
    "    \"리처드 닉슨은 1953년부터 1961년까지 제43대 미국 부통령이었습니다.\",\n",
    "    \"미국 일리노이주 시카고 시 북서쪽, 시 외곽의 쿡 카운티에 위치해 있습니다.\",\n",
    "    \"사용자의 지역 정보가 없으므로 정확한 수치를 알 수 없습니다. 포털 사이트나 환경부 ‘에어코리아’에서 실시간 확인 가능합니다.\"\n",
    "]\n",
    "\n",
    "# BERTScore 계산 (기본 모델: roberta-large, 한국어는 아래 참고)\n",
    "P, R, F1 = score(list_generated_responses, list_references, model_type=\"klue/roberta-base\", num_layers=12, verbose=True)\n",
    "\n",
    "# 각 문장별 점수 출력\n",
    "for i, (p, r, f1) in enumerate(zip(P, R, F1)):\n",
    "    print(f\"\\n🔹 예제 {i+1}\")\n",
    "    print(f\"  📝 질문: {list_prompt_original[i]}\")\n",
    "    print(f\"  🤖 응답: {list_generated_responses[i]}\")\n",
    "    print(f\"  ✅ 정답: {list_references[i]}\")\n",
    "    print(f\"  📌 BERTScore - Precision: {p:.4f}, Recall: {r:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "# 평균 F1 출력\n",
    "print(f\"\\n📊 BERTScore F1 평균: {F1.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e913cd6",
   "metadata": {},
   "source": [
    "## PPO - BERTScore 평가\n",
    "\n",
    "PPO모델보다 SFT모델이 더 좋은 성능을 보이고 있다.\n",
    "\n",
    "정성평가 정량평가가 어느정도 일치한다는것을 확인할 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914124b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
